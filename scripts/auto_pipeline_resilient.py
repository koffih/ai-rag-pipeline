#!/usr/bin/env python3
"""
Pipeline RAG r√©silient avec d√©placement automatique des fichiers apr√®s chaque √©tape
"""

import os
import time
import shutil
import sys
import subprocess
import logging
import json
from datetime import datetime
from pathlib import Path
import signal
import threading

# Configuration des logs
LOG_FILE = os.path.join(os.path.dirname(__file__), '..', 'resilient_pipeline.log')
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# Configuration des r√©pertoires
WATCH_DIRECTORY = "/home/koffi/rag_project/extractable_files"
DONE_DIRECTORY = os.path.join(WATCH_DIRECTORY, "done")
PROCESSING_DIRECTORY = os.path.join(WATCH_DIRECTORY, "processing")
FAILED_DIRECTORY = os.path.join(WATCH_DIRECTORY, "failed")
BACKUP_DIRECTORY = os.path.join(WATCH_DIRECTORY, "backup")

# Scripts du pipeline
RAG_SCRIPTS_DIR = os.path.dirname(os.path.abspath(__file__))
VECTORIZE_SCRIPT = os.path.join(RAG_SCRIPTS_DIR, "vectorize_books.py")
TOPIC_SCRIPT = os.path.join(RAG_SCRIPTS_DIR, "topic_generator.py")
ARTICLE_SCRIPT = os.path.join(RAG_SCRIPTS_DIR, "generate_articles_from_supabase.py")

SUPPORTED_EXTENSIONS = (".pdf", ".epub", ".mobi", ".azw3", ".txt", ".docx")

# √âtat de traitement par fichier
processing_state = {}

def setup_directories():
    """Cr√©er tous les r√©pertoires n√©cessaires"""
    directories = [DONE_DIRECTORY, PROCESSING_DIRECTORY, FAILED_DIRECTORY, BACKUP_DIRECTORY]
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        logging.info(f"R√©pertoire cr√©√©/v√©rifi√©: {directory}")

def safe_file_move(src, dst, max_retries=3):
    """D√©placement s√©curis√© avec retry et backup"""
    for attempt in range(max_retries):
        try:
            if os.path.exists(src):
                # Cr√©er un backup avant d√©placement
                backup_path = os.path.join(BACKUP_DIRECTORY, os.path.basename(src))
                shutil.copy2(src, backup_path)
                
                # D√©placer le fichier
                shutil.move(src, dst)
                logging.info(f"Fichier d√©plac√© avec succ√®s: {src} ‚Üí {dst}")
                return True
            else:
                logging.warning(f"Fichier source non trouv√©: {src}")
                return False
        except Exception as e:
            logging.error(f"Tentative {attempt + 1} √©chou√©e pour {src}: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # Backoff exponentiel
            else:
                logging.error(f"√âchec d√©finitif du d√©placement: {src}")
                return False
    return False

def check_file_in_chroma(filename):
    """V√©rifier si un fichier est d√©j√† vectoris√© dans ChromaDB"""
    try:
        from langchain_community.vectorstores import Chroma
        from langchain_community.embeddings import HuggingFaceEmbeddings
        
        CHROMA_DIR = "/home/koffi/rag_scripts/chroma_store"
        embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        vectorstore = Chroma(persist_directory=CHROMA_DIR, embedding_function=embedding_model)
        
        # R√©cup√©rer tous les documents
        docs = vectorstore.get()["metadatas"]
        texts = vectorstore.get()["documents"]
        
        # V√©rifier si le fichier est pr√©sent
        for meta in docs:
            if meta.get("source") == filename:
                return True
        return False
    except Exception as e:
        logging.error(f"Erreur lors de la v√©rification ChromaDB: {e}")
        return False

def process_file_resilient(file_path):
    """Traitement r√©silient d'un fichier avec d√©placement apr√®s chaque √©tape"""
    filename = os.path.basename(file_path)
    file_id = f"{filename}_{int(time.time())}"
    
    print(f"\n" + "="*80)
    print(f"üöÄ TRAITEMENT R√âSILIENT: {filename}")
    print(f"üÜî ID: {file_id}")
    print(f"‚è∞ D√âBUT: {datetime.now().strftime('%H:%M:%S')}")
    print("="*80)
    
    # Initialiser l'√©tat de traitement
    processing_state[file_id] = {
        'filename': filename,
        'start_time': datetime.now(),
        'steps_completed': [],
        'current_step': 'init',
        'errors': []
    }
    
    # V√©rifier que le fichier existe
    if not os.path.exists(file_path):
        error_msg = f"Fichier non trouv√©: {file_path}"
        processing_state[file_id]['errors'].append(error_msg)
        logging.error(error_msg)
        print(f"‚ùå {error_msg}")
        return False
    
    # V√©rifier si d√©j√† vectoris√©
    if check_file_in_chroma(filename):
        print(f"‚úÖ Fichier d√©j√† vectoris√©: {filename}")
        # D√©placer directement vers done
        dest = os.path.join(DONE_DIRECTORY, filename)
        if safe_file_move(file_path, dest):
            processing_state[file_id]['steps_completed'].append('already_vectorized')
            print(f"üì¶ Fichier d√©plac√© vers done: {dest}")
            return True
    
    try:
        # √âTAPE 1: Vectorisation
        processing_state[file_id]['current_step'] = 'vectorization'
        print(f"\nüîÑ [√âTAPE 1/3] VECTORISATION")
        
        result = subprocess.run([sys.executable, VECTORIZE_SCRIPT, file_path], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(f"‚úÖ Vectorisation r√©ussie")
            processing_state[file_id]['steps_completed'].append('vectorization')
            
            # D√©placer vers processing apr√®s vectorisation r√©ussie
            processing_path = os.path.join(PROCESSING_DIRECTORY, filename)
            if safe_file_move(file_path, processing_path):
                file_path = processing_path  # Mettre √† jour le chemin
                print(f"üì¶ Fichier d√©plac√© vers processing apr√®s vectorisation")
        else:
            error_msg = f"Erreur vectorisation: {result.stderr}"
            processing_state[file_id]['errors'].append(error_msg)
            print(f"‚ùå {error_msg}")
            # D√©placer vers failed
            failed_path = os.path.join(FAILED_DIRECTORY, filename)
            safe_file_move(file_path, failed_path)
            return False
        
        # √âTAPE 2: G√©n√©ration des topics
        processing_state[file_id]['current_step'] = 'topics'
        print(f"\nüîÑ [√âTAPE 2/3] G√âN√âRATION DES TOPICS")
        
        result = subprocess.run([sys.executable, TOPIC_SCRIPT, filename], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(f"‚úÖ G√©n√©ration topics r√©ussie")
            processing_state[file_id]['steps_completed'].append('topics')
        else:
            error_msg = f"Erreur g√©n√©ration topics: {result.stderr}"
            processing_state[file_id]['errors'].append(error_msg)
            print(f"‚ö†Ô∏è {error_msg}")
            # Continuer quand m√™me car la vectorisation est r√©ussie
        
        # √âTAPE 3: G√©n√©ration des articles
        processing_state[file_id]['current_step'] = 'articles'
        print(f"\nüîÑ [√âTAPE 3/3] G√âN√âRATION DES ARTICLES")
        
        result = subprocess.run([sys.executable, ARTICLE_SCRIPT, "100"], 
                              capture_output=True, text=True, timeout=1800)
        
        if result.returncode == 0:
            print(f"‚úÖ G√©n√©ration articles r√©ussie")
            processing_state[file_id]['steps_completed'].append('articles')
        else:
            error_msg = f"Erreur g√©n√©ration articles: {result.stderr}"
            processing_state[file_id]['errors'].append(error_msg)
            print(f"‚ö†Ô∏è {error_msg}")
            # Continuer car la vectorisation et les topics sont r√©ussis
        
        # FINALISATION: D√©placer vers done
        processing_state[file_id]['current_step'] = 'finalization'
        dest = os.path.join(DONE_DIRECTORY, filename)
        
        if safe_file_move(file_path, dest):
            processing_state[file_id]['steps_completed'].append('completed')
            processing_state[file_id]['end_time'] = datetime.now()
            
            print(f"\n‚úÖ SUCC√àS COMPLET pour {filename}")
            print(f"üìä √âtapes r√©ussies: {', '.join(processing_state[file_id]['steps_completed'])}")
            print(f"üìÅ Fichier final: {dest}")
            print(f"‚è∞ Dur√©e totale: {processing_state[file_id]['end_time'] - processing_state[file_id]['start_time']}")
            
            # Sauvegarder l'√©tat de traitement
            save_processing_state(file_id)
            return True
        else:
            error_msg = "√âchec du d√©placement final"
            processing_state[file_id]['errors'].append(error_msg)
            print(f"‚ùå {error_msg}")
            return False
            
    except subprocess.TimeoutExpired as e:
        error_msg = f"Timeout pour {filename}: {e}"
        processing_state[file_id]['errors'].append(error_msg)
        print(f"‚è±Ô∏è {error_msg}")
        
        # D√©placer vers failed en cas de timeout
        failed_path = os.path.join(FAILED_DIRECTORY, filename)
        safe_file_move(file_path, failed_path)
        return False
        
    except Exception as e:
        error_msg = f"Erreur critique pour {filename}: {e}"
        processing_state[file_id]['errors'].append(error_msg)
        print(f"‚ùå {error_msg}")
        logging.error(error_msg)
        
        # D√©placer vers failed
        failed_path = os.path.join(FAILED_DIRECTORY, filename)
        safe_file_move(file_path, failed_path)
        return False

def save_processing_state(file_id):
    """Sauvegarder l'√©tat de traitement dans un fichier JSON"""
    try:
        state_file = os.path.join(WATCH_DIRECTORY, f"processing_state_{file_id}.json")
        with open(state_file, 'w') as f:
            json.dump(processing_state[file_id], f, default=str, indent=2)
        logging.info(f"√âtat de traitement sauvegard√©: {state_file}")
    except Exception as e:
        logging.error(f"Erreur sauvegarde √©tat: {e}")

def count_files_by_status():
    """Compter les fichiers par statut"""
    counts = {
        'pending': 0,
        'processing': 0,
        'done': 0,
        'failed': 0
    }
    
    # Fichiers en attente
    for filename in os.listdir(WATCH_DIRECTORY):
        if filename not in ['done', 'processing', 'failed', 'backup']:
            full_path = os.path.join(WATCH_DIRECTORY, filename)
            if os.path.isfile(full_path) and filename.lower().endswith(SUPPORTED_EXTENSIONS):
                counts['pending'] += 1
    
    # Fichiers en cours de traitement
    if os.path.exists(PROCESSING_DIRECTORY):
        counts['processing'] = len([f for f in os.listdir(PROCESSING_DIRECTORY) 
                                   if os.path.isfile(os.path.join(PROCESSING_DIRECTORY, f))])
    
    # Fichiers termin√©s
    if os.path.exists(DONE_DIRECTORY):
        counts['done'] = len([f for f in os.listdir(DONE_DIRECTORY) 
                             if os.path.isfile(os.path.join(DONE_DIRECTORY, f))])
    
    # Fichiers √©chou√©s
    if os.path.exists(FAILED_DIRECTORY):
        counts['failed'] = len([f for f in os.listdir(FAILED_DIRECTORY) 
                               if os.path.isfile(os.path.join(FAILED_DIRECTORY, f))])
    
    return counts

def process_existing_files(only_one=False):
    """Traiter les fichiers existants"""
    print("üîÅ V√©rification des fichiers existants...")
    
    counts = count_files_by_status()
    print(f"üìä √âtat actuel:")
    print(f"  - En attente: {counts['pending']}")
    print(f"  - En cours: {counts['processing']}")
    print(f"  - Termin√©s: {counts['done']}")
    print(f"  - √âchou√©s: {counts['failed']}")
    
    processed = 0
    
    # Traiter les fichiers en attente
    for filename in os.listdir(WATCH_DIRECTORY):
        if filename not in ['done', 'processing', 'failed', 'backup']:
            full_path = os.path.join(WATCH_DIRECTORY, filename)
            if os.path.isfile(full_path) and filename.lower().endswith(SUPPORTED_EXTENSIONS):
                print(f"\nüéØ Traitement du fichier: {filename}")
                if process_file_resilient(full_path):
                    processed += 1
                else:
                    print(f"‚ùå √âchec du traitement: {filename}")
                
                if only_one:
                    break
    
    print(f"\nüìä {processed} fichiers trait√©s")
    return processed

def main():
    """Fonction principale"""
    print("üõ°Ô∏è Pipeline RAG R√©silient")
    print("=" * 50)
    
    # Configuration
    setup_directories()
    
    # Traitement des fichiers existants
    process_existing_files()
    
    print("\n‚úÖ Pipeline r√©silient termin√©")
    print(f"üìù Logs d√©taill√©s: {LOG_FILE}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--one', action='store_true', help='Traiter un seul fichier')
    args = parser.parse_args()
    
    if args.one:
        process_existing_files(only_one=True)
    else:
        main() 