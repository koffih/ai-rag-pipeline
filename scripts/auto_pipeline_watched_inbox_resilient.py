#!/usr/bin/env python3
"""
Pipeline RAG r√©silient pour watched_inbox avec gestion de tous les types de fichiers
"""

import os
import time
import shutil
import sys
import subprocess
import logging
import json
import mimetypes
from datetime import datetime
from pathlib import Path
import signal
import threading

# Configuration des logs
LOG_FILE = os.path.join(os.path.dirname(__file__), '..', 'watched_inbox_resilient.log')
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# Configuration des r√©pertoires
WATCH_DIRECTORY = "/home/koffi/rag_project/watched_inbox"
DONE_DIRECTORY = os.path.join(WATCH_DIRECTORY, "done")
PROCESSING_DIRECTORY = os.path.join(WATCH_DIRECTORY, "processing")
FAILED_DIRECTORY = os.path.join(WATCH_DIRECTORY, "failed")
BACKUP_DIRECTORY = os.path.join(WATCH_DIRECTORY, "backup")
CONVERTED_DIRECTORY = os.path.join(WATCH_DIRECTORY, "converted")

# Scripts du pipeline
RAG_SCRIPTS_DIR = os.path.dirname(os.path.abspath(__file__))
VECTORIZE_SCRIPT = os.path.join(RAG_SCRIPTS_DIR, "vectorize_books.py")
TOPIC_SCRIPT = os.path.join(RAG_SCRIPTS_DIR, "topic_generator.py")
ARTICLE_SCRIPT = os.path.join(RAG_SCRIPTS_DIR, "generate_articles_from_supabase.py")

# Types de fichiers support√©s
SUPPORTED_EXTENSIONS = {
    'text': (".pdf", ".txt", ".docx", ".rtf", ".odt", ".html", ".htm"),
    'ebook': (".epub", ".mobi", ".azw", ".azw3", ".fb2", ".lit", ".pdb"),
    'audio': (".mp3", ".wav", ".m4a", ".flac", ".ogg", ".aac"),
    'image': (".jpg", ".jpeg", ".png", ".tiff", ".bmp")
}

# √âtat de traitement par fichier
processing_state = {}

def setup_directories():
    """Cr√©er tous les r√©pertoires n√©cessaires"""
    directories = [DONE_DIRECTORY, PROCESSING_DIRECTORY, FAILED_DIRECTORY, BACKUP_DIRECTORY, CONVERTED_DIRECTORY]
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        logging.info(f"R√©pertoire cr√©√©/v√©rifi√©: {directory}")

def safe_file_move(src, dst, max_retries=3):
    """D√©placement s√©curis√© avec retry et backup"""
    for attempt in range(max_retries):
        try:
            if os.path.exists(src):
                # Cr√©er un backup avant d√©placement
                backup_path = os.path.join(BACKUP_DIRECTORY, os.path.basename(src))
                shutil.copy2(src, backup_path)
                
                # D√©placer le fichier
                shutil.move(src, dst)
                logging.info(f"Fichier d√©plac√© avec succ√®s: {src} ‚Üí {dst}")
                return True
            else:
                logging.warning(f"Fichier source non trouv√©: {src}")
                return False
        except Exception as e:
            logging.error(f"Tentative {attempt + 1} √©chou√©e pour {src}: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # Backoff exponentiel
            else:
                logging.error(f"√âchec d√©finitif du d√©placement: {src}")
                return False
    return False

def detect_file_type(filepath):
    """D√©tecter le type de fichier"""
    ext = os.path.splitext(filepath)[1].lower()
    
    for file_type, extensions in SUPPORTED_EXTENSIONS.items():
        if ext in extensions:
            return file_type
    
    return 'unknown'

def convert_audio_to_text(audio_path, output_path):
    """Convertir un fichier audio en texte via Whisper"""
    try:
        import whisper
        print(f"üéµ Transcription audio: {os.path.basename(audio_path)}")
        
        model = whisper.load_model("base")
        result = model.transcribe(audio_path)
        text = result["text"]
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(text)
        
        print(f"‚úÖ Transcription r√©ussie: {len(text)} caract√®res")
        return True
    except Exception as e:
        print(f"‚ùå Erreur transcription: {e}")
        return False

def convert_ebook_to_text(ebook_path, output_path):
    """Convertir un eBook en texte"""
    try:
        # Essayer d'abord avec Calibre
        pdf_path = os.path.join(CONVERTED_DIRECTORY, os.path.splitext(os.path.basename(ebook_path))[0] + '.pdf')
        
        print(f"üìö Conversion eBook: {os.path.basename(ebook_path)}")
        
        # Conversion en PDF
        result = subprocess.run(['ebook-convert', ebook_path, pdf_path], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0 and os.path.exists(pdf_path):
            # Extraction texte du PDF
            from langchain_community.document_loaders import PyPDFLoader
            loader = PyPDFLoader(pdf_path)
            docs = loader.load()
            text = '\n'.join([doc.page_content for doc in docs])
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(text)
            
            print(f"‚úÖ Conversion eBook r√©ussie: {len(text)} caract√®res")
            return True
        else:
            print(f"‚ùå Erreur conversion eBook: {result.stderr}")
            return False
    except Exception as e:
        print(f"‚ùå Erreur conversion eBook: {e}")
        return False

def convert_document_to_text(doc_path, output_path):
    """Convertir un document en texte"""
    try:
        print(f"üìÑ Conversion document: {os.path.basename(doc_path)}")
        
        # Utiliser pandoc pour la conversion
        result = subprocess.run(['pandoc', doc_path, '-t', 'plain', '-o', output_path], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            # V√©rifier que le fichier contient du texte
            with open(output_path, 'r', encoding='utf-8') as f:
                text = f.read().strip()
                if text and len(text) > 100:
                    print(f"‚úÖ Conversion document r√©ussie: {len(text)} caract√®res")
                    return True
        
        print(f"‚ùå Erreur conversion document: {result.stderr}")
        return False
    except Exception as e:
        print(f"‚ùå Erreur conversion document: {e}")
        return False

def convert_pdf_with_ocr(pdf_path, output_path):
    """Convertir un PDF en texte avec OCR si n√©cessaire"""
    try:
        print(f"üìÑ Traitement PDF: {os.path.basename(pdf_path)}")
        
        # Essayer d'abord l'extraction normale
        from langchain_community.document_loaders import PyPDFLoader
        loader = PyPDFLoader(pdf_path)
        docs = loader.load()
        text = '\n'.join([doc.page_content for doc in docs])
        
        # Si pas de texte, essayer l'OCR
        if not text.strip():
            print(f"üîÑ PDF sans texte, lancement OCR...")
            from pdf2image import convert_from_path
            import pytesseract
            
            images = convert_from_path(pdf_path)
            ocr_text = ""
            for img in images:
                ocr_text += pytesseract.image_to_string(img, lang="fra")
            text = ocr_text
            print(f"‚úÖ OCR termin√©: {len(text)} caract√®res")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(text)
        
        print(f"‚úÖ Traitement PDF r√©ussi: {len(text)} caract√®res")
        return True
    except Exception as e:
        print(f"‚ùå Erreur traitement PDF: {e}")
        return False

def convert_file_to_text(file_path):
    """Convertir un fichier en texte selon son type"""
    filename = os.path.basename(file_path)
    file_type = detect_file_type(file_path)
    
    # Cr√©er le fichier de sortie
    txt_filename = os.path.splitext(filename)[0] + '.txt'
    txt_path = os.path.join(CONVERTED_DIRECTORY, txt_filename)
    
    print(f"\nüîÑ CONVERSION: {filename} (Type: {file_type})")
    
    success = False
    
    if file_type == 'text':
        if filename.lower().endswith('.pdf'):
            success = convert_pdf_with_ocr(file_path, txt_path)
        elif filename.lower().endswith('.txt'):
            # Copier directement
            shutil.copy2(file_path, txt_path)
            success = True
        else:
            success = convert_document_to_text(file_path, txt_path)
    
    elif file_type == 'ebook':
        success = convert_ebook_to_text(file_path, txt_path)
    
    elif file_type == 'audio':
        success = convert_audio_to_text(file_path, txt_path)
    
    else:
        print(f"‚ùå Type de fichier non support√©: {file_type}")
        return None
    
    if success and os.path.exists(txt_path):
        return txt_path
    else:
        return None

def check_file_in_chroma(filename):
    """V√©rifier si un fichier est d√©j√† vectoris√© dans ChromaDB"""
    try:
        from langchain_community.vectorstores import Chroma
        from langchain_community.embeddings import HuggingFaceEmbeddings
        
        CHROMA_DIR = "/home/koffi/rag_scripts/chroma_store"
        embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        vectorstore = Chroma(persist_directory=CHROMA_DIR, embedding_function=embedding_model)
        
        # R√©cup√©rer tous les documents
        docs = vectorstore.get()["metadatas"]
        
        # V√©rifier si le fichier est pr√©sent
        for meta in docs:
            if meta.get("source") == filename:
                return True
        return False
    except Exception as e:
        logging.error(f"Erreur lors de la v√©rification ChromaDB: {e}")
        return False

def process_file_resilient(file_path):
    """Traitement r√©silient d'un fichier avec conversion et d√©placement automatique"""
    filename = os.path.basename(file_path)
    file_id = f"{filename}_{int(time.time())}"
    
    print(f"\n" + "="*80)
    print(f"üöÄ TRAITEMENT R√âSILIENT WATCHED_INBOX: {filename}")
    print(f"üÜî ID: {file_id}")
    print(f"‚è∞ D√âBUT: {datetime.now().strftime('%H:%M:%S')}")
    print("="*80)
    
    # Initialiser l'√©tat de traitement
    processing_state[file_id] = {
        'filename': filename,
        'start_time': datetime.now(),
        'steps_completed': [],
        'current_step': 'init',
        'errors': []
    }
    
    # V√©rifier que le fichier existe
    if not os.path.exists(file_path):
        error_msg = f"Fichier non trouv√©: {file_path}"
        processing_state[file_id]['errors'].append(error_msg)
        logging.error(error_msg)
        print(f"‚ùå {error_msg}")
        return False
    
    # V√©rifier si d√©j√† vectoris√©
    if check_file_in_chroma(filename):
        print(f"‚úÖ Fichier d√©j√† vectoris√©: {filename}")
        # D√©placer directement vers done
        dest = os.path.join(DONE_DIRECTORY, filename)
        if safe_file_move(file_path, dest):
            processing_state[file_id]['steps_completed'].append('already_vectorized')
            print(f"üì¶ Fichier d√©plac√© vers done: {dest}")
            return True
    
    try:
        # √âTAPE 1: Conversion en texte
        processing_state[file_id]['current_step'] = 'conversion'
        print(f"\nüîÑ [√âTAPE 1/4] CONVERSION EN TEXTE")
        
        txt_path = convert_file_to_text(file_path)
        
        if txt_path and os.path.exists(txt_path):
            print(f"‚úÖ Conversion r√©ussie")
            processing_state[file_id]['steps_completed'].append('conversion')
            
            # D√©placer le fichier original vers processing
            processing_path = os.path.join(PROCESSING_DIRECTORY, filename)
            if safe_file_move(file_path, processing_path):
                file_path = processing_path  # Mettre √† jour le chemin
                print(f"üì¶ Fichier original d√©plac√© vers processing")
        else:
            error_msg = "√âchec de la conversion en texte"
            processing_state[file_id]['errors'].append(error_msg)
            print(f"‚ùå {error_msg}")
            # D√©placer vers failed
            failed_path = os.path.join(FAILED_DIRECTORY, filename)
            safe_file_move(file_path, failed_path)
            return False
        
        # √âTAPE 2: Vectorisation
        processing_state[file_id]['current_step'] = 'vectorization'
        print(f"\nüîÑ [√âTAPE 2/4] VECTORISATION")
        
        result = subprocess.run([sys.executable, VECTORIZE_SCRIPT, txt_path], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(f"‚úÖ Vectorisation r√©ussie")
            processing_state[file_id]['steps_completed'].append('vectorization')
        else:
            error_msg = f"Erreur vectorisation: {result.stderr}"
            processing_state[file_id]['errors'].append(error_msg)
            print(f"‚ùå {error_msg}")
            # D√©placer vers failed
            failed_path = os.path.join(FAILED_DIRECTORY, filename)
            safe_file_move(file_path, failed_path)
            return False
        
        # √âTAPE 3: G√©n√©ration des topics
        processing_state[file_id]['current_step'] = 'topics'
        print(f"\nüîÑ [√âTAPE 3/4] G√âN√âRATION DES TOPICS")
        
        result = subprocess.run([sys.executable, TOPIC_SCRIPT, filename], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(f"‚úÖ G√©n√©ration topics r√©ussie")
            processing_state[file_id]['steps_completed'].append('topics')
        else:
            error_msg = f"Erreur g√©n√©ration topics: {result.stderr}"
            processing_state[file_id]['errors'].append(error_msg)
            print(f"‚ö†Ô∏è {error_msg}")
            # Continuer quand m√™me car la vectorisation est r√©ussie
        
        # √âTAPE 4: G√©n√©ration des articles
        processing_state[file_id]['current_step'] = 'articles'
        print(f"\nüîÑ [√âTAPE 4/4] G√âN√âRATION DES ARTICLES")
        
        result = subprocess.run([sys.executable, ARTICLE_SCRIPT, "100"], 
                              capture_output=True, text=True, timeout=1800)
        
        if result.returncode == 0:
            print(f"‚úÖ G√©n√©ration articles r√©ussie")
            processing_state[file_id]['steps_completed'].append('articles')
        else:
            error_msg = f"Erreur g√©n√©ration articles: {result.stderr}"
            processing_state[file_id]['errors'].append(error_msg)
            print(f"‚ö†Ô∏è {error_msg}")
            # Continuer car la vectorisation et les topics sont r√©ussis
        
        # FINALISATION: D√©placer vers done
        processing_state[file_id]['current_step'] = 'finalization'
        dest = os.path.join(DONE_DIRECTORY, filename)
        
        if safe_file_move(file_path, dest):
            processing_state[file_id]['steps_completed'].append('completed')
            processing_state[file_id]['end_time'] = datetime.now()
            
            print(f"\n‚úÖ SUCC√àS COMPLET pour {filename}")
            print(f"üìä √âtapes r√©ussies: {', '.join(processing_state[file_id]['steps_completed'])}")
            print(f"üìÅ Fichier final: {dest}")
            print(f"‚è∞ Dur√©e totale: {processing_state[file_id]['end_time'] - processing_state[file_id]['start_time']}")
            
            # Sauvegarder l'√©tat de traitement
            save_processing_state(file_id)
            return True
        else:
            error_msg = "√âchec du d√©placement final"
            processing_state[file_id]['errors'].append(error_msg)
            print(f"‚ùå {error_msg}")
            return False
            
    except subprocess.TimeoutExpired as e:
        error_msg = f"Timeout pour {filename}: {e}"
        processing_state[file_id]['errors'].append(error_msg)
        print(f"‚è±Ô∏è {error_msg}")
        
        # D√©placer vers failed en cas de timeout
        failed_path = os.path.join(FAILED_DIRECTORY, filename)
        safe_file_move(file_path, failed_path)
        return False
        
    except Exception as e:
        error_msg = f"Erreur critique pour {filename}: {e}"
        processing_state[file_id]['errors'].append(error_msg)
        print(f"‚ùå {error_msg}")
        logging.error(error_msg)
        
        # D√©placer vers failed
        failed_path = os.path.join(FAILED_DIRECTORY, filename)
        safe_file_move(file_path, failed_path)
        return False

def save_processing_state(file_id):
    """Sauvegarder l'√©tat de traitement dans un fichier JSON"""
    try:
        state_file = os.path.join(WATCH_DIRECTORY, f"processing_state_{file_id}.json")
        with open(state_file, 'w') as f:
            json.dump(processing_state[file_id], f, default=str, indent=2)
        logging.info(f"√âtat de traitement sauvegard√©: {state_file}")
    except Exception as e:
        logging.error(f"Erreur sauvegarde √©tat: {e}")

def count_files_by_status():
    """Compter les fichiers par statut"""
    counts = {
        'pending': 0,
        'processing': 0,
        'done': 0,
        'failed': 0
    }
    
    # Fichiers en attente
    for filename in os.listdir(WATCH_DIRECTORY):
        if filename not in ['done', 'processing', 'failed', 'backup', 'converted']:
            full_path = os.path.join(WATCH_DIRECTORY, filename)
            if os.path.isfile(full_path):
                # V√©rifier si c'est un type support√©
                file_type = detect_file_type(full_path)
                if file_type != 'unknown':
                    counts['pending'] += 1
    
    # Fichiers en cours de traitement
    if os.path.exists(PROCESSING_DIRECTORY):
        counts['processing'] = len([f for f in os.listdir(PROCESSING_DIRECTORY) 
                                   if os.path.isfile(os.path.join(PROCESSING_DIRECTORY, f))])
    
    # Fichiers termin√©s
    if os.path.exists(DONE_DIRECTORY):
        counts['done'] = len([f for f in os.listdir(DONE_DIRECTORY) 
                             if os.path.isfile(os.path.join(DONE_DIRECTORY, f))])
    
    # Fichiers √©chou√©s
    if os.path.exists(FAILED_DIRECTORY):
        counts['failed'] = len([f for f in os.listdir(FAILED_DIRECTORY) 
                               if os.path.isfile(os.path.join(FAILED_DIRECTORY, f))])
    
    return counts

def process_existing_files(only_one=False):
    """Traiter les fichiers existants"""
    print("üîÅ V√©rification des fichiers existants...")
    
    counts = count_files_by_status()
    print(f"üìä √âtat actuel:")
    print(f"  - En attente: {counts['pending']}")
    print(f"  - En cours: {counts['processing']}")
    print(f"  - Termin√©s: {counts['done']}")
    print(f"  - √âchou√©s: {counts['failed']}")
    
    processed = 0
    
    # Traiter les fichiers en attente
    for filename in os.listdir(WATCH_DIRECTORY):
        if filename not in ['done', 'processing', 'failed', 'backup', 'converted']:
            full_path = os.path.join(WATCH_DIRECTORY, filename)
            if os.path.isfile(full_path):
                # V√©rifier si c'est un type support√©
                file_type = detect_file_type(full_path)
                if file_type != 'unknown':
                    print(f"\nüéØ Traitement du fichier: {filename} (Type: {file_type})")
                    if process_file_resilient(full_path):
                        processed += 1
                    else:
                        print(f"‚ùå √âchec du traitement: {filename}")
                    
                    if only_one:
                        break
    
    print(f"\nüìä {processed} fichiers trait√©s")
    return processed

def main():
    """Fonction principale"""
    print("üõ°Ô∏è Pipeline RAG R√©silient - Watched Inbox")
    print("=" * 50)
    
    # Configuration
    setup_directories()
    
    # Traitement des fichiers existants
    process_existing_files()
    
    print("\n‚úÖ Pipeline r√©silient termin√©")
    print(f"üìù Logs d√©taill√©s: {LOG_FILE}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--one', action='store_true', help='Traiter un seul fichier')
    args = parser.parse_args()
    
    if args.one:
        process_existing_files(only_one=True)
    else:
        main() 